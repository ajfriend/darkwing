[
  {
    "objectID": "related.html",
    "href": "related.html",
    "title": "Related Projects",
    "section": "",
    "text": "Pandas\nPolars\nIbis\nDuckDB\n\nDuckDB’s SQL improvements\n\nPRQL",
    "crumbs": [
      "Related Projects"
    ]
  },
  {
    "objectID": "tut_lazy.html",
    "href": "tut_lazy.html",
    "title": "Lazy Evaluation Tutorial",
    "section": "",
    "text": "Introduction\nSince duckboat is based on the DuckDB relational API, all expressions are “lazy” in that they defer evaluation until a result or a data preview is requested. This allows us to build up complex data processing pipelines iteratively, but without needing to compute extranous intermediate results. Instead, under the hood, DuckDB will gather the sequence of steps and pass it to a query optimizer, which will apply optimizations like predicate and projection pushdown. The full operation will be executed by DuckDB making full use of all the cores available on your machine, streaming the operations if possible, and even spilling to disk if the operation is too large to fit in memory.\n\nimport duckboat as uck\n\n\nt0 = uck.Table('data/yellow_tripdata_2010-01.parquet')\nt0.columns\n\n['vendor_id',\n 'pickup_datetime',\n 'dropoff_datetime',\n 'passenger_count',\n 'trip_distance',\n 'pickup_longitude',\n 'pickup_latitude',\n 'rate_code',\n 'store_and_fwd_flag',\n 'dropoff_longitude',\n 'dropoff_latitude',\n 'payment_type',\n 'fare_amount',\n 'surcharge',\n 'mta_tax',\n 'tip_amount',\n 'tolls_amount',\n 'total_amount']\n\n\n\ncount_rows = \"select format('{:.2e}', 1.0*count(*)) as num_rows\"\nt0.do(count_rows)\n\n┌──────────┐\n│ num_rows │\n│ varchar  │\n├──────────┤\n│ 1.49e+07 │\n└──────────┘\n\n\nThe following code is executed instantaneously, since no query operations are performed.\n\nt1 = t0.do(\n    'where (pickup_longitude != 0) and (pickup_latitude != 0)',\n    'where total_amount &gt; 0',\n\n    'select *, h3_latlng_to_cell(pickup_latitude, pickup_longitude, 12) as hexid',\n    'select * replace ( h3_h3_to_string(hexid) as hexid )',\n    'select cast(pickup_datetime as timestamp) as ts, hexid, total_amount as amt',\n)\n\n\n\nLazy operations\nListing the table as the last expression in a Jupyter notebook makes Jupyter try to represent the table, which triggers DuckDB do either compute the full table, or, in the case that the table has many rows, compute just enough rows to show a preview. In many instances, the preview is faster to compute.\nThe following is still fast, but just a bit slower than the previous cell, since this is where the query associated with the operations above is actually performed.\n\nt1\n\n┌─────────────────────┬─────────────────┬───────────────────┐\n│         ts          │      hexid      │        amt        │\n│      timestamp      │     varchar     │      double       │\n├─────────────────────┼─────────────────┼───────────────────┤\n│ 2010-01-26 07:41:00 │ 8c2a100d45b01ff │               5.0 │\n│ 2010-01-30 23:31:00 │ 8c2a107258e61ff │              16.3 │\n│ 2010-01-18 20:22:20 │ 8c2a1008b82b5ff │              12.7 │\n│ 2010-01-09 01:18:00 │ 8c2a100d65653ff │              14.3 │\n│ 2010-01-18 19:10:14 │ 8c2a100d22945ff │              6.67 │\n│ 2010-01-17 09:18:00 │ 8c2a10725ac5bff │               6.6 │\n│ 2010-01-09 13:49:00 │ 8c2a100d620b7ff │               7.4 │\n│ 2010-01-09 00:25:00 │ 8c2a1072c86abff │              12.3 │\n│ 2010-01-27 18:15:00 │ 8c2a100d2bb69ff │              12.0 │\n│ 2010-01-08 16:05:00 │ 8c2a107250403ff │              10.2 │\n│          ·          │        ·        │                ·  │\n│          ·          │        ·        │                ·  │\n│          ·          │        ·        │                ·  │\n│ 2010-01-05 16:50:04 │ 8c2a100d2ac47ff │               6.0 │\n│ 2010-01-03 01:30:26 │ 8c2a100d63201ff │               8.3 │\n│ 2010-01-26 18:10:00 │ 8c2a100d60839ff │              13.8 │\n│ 2010-01-26 20:23:00 │ 8c2a1072c9533ff │              15.5 │\n│ 2010-01-07 19:25:00 │ 8c2a100d654c7ff │               6.8 │\n│ 2010-01-03 19:00:53 │ 8c2a1008b368dff │ 8.199999999999998 │\n│ 2010-01-28 14:10:00 │ 8c2a100d666e9ff │               6.4 │\n│ 2010-01-23 15:52:00 │ 8c2a1008bad2bff │             30.79 │\n│ 2010-01-27 15:32:00 │ 8c2a100d2280bff │             55.07 │\n│ 2010-01-01 02:58:00 │ 8c2a100d2aaa9ff │               7.9 │\n├─────────────────────┴─────────────────┴───────────────────┤\n│ ? rows (&gt;9999 rows, 20 shown)                   3 columns │\n└───────────────────────────────────────────────────────────┘\n\n\n\nt2 = t1.alias('tbl1').do(\"\"\"\nselect\n      a.hexid\n    , a.ts as ts1\n    , b.ts as ts2\n    , a.amt as amt1\n    , b.amt as amt2\nfrom\n    tbl1 as a\ninner join\n    tbl1 as b\nusing\n    (hexid)\n\"\"\").hide()\n\nEven though the computation for t2 is complex, we can compute a preview fairly quickly. The following runs in about 2 seconds on my laptop.\n\nt2.show()\n\n┌─────────────────┬─────────────────────┬─────────────────────┬────────┬───────────────────┐\n│      hexid      │         ts1         │         ts2         │  amt1  │       amt2        │\n│     varchar     │      timestamp      │      timestamp      │ double │      double       │\n├─────────────────┼─────────────────────┼─────────────────────┼────────┼───────────────────┤\n│ 8c2a100d45b01ff │ 2010-01-26 07:41:00 │ 2010-01-27 20:32:00 │    5.0 │              48.5 │\n│ 8c2a107258e61ff │ 2010-01-30 23:31:00 │ 2010-01-06 16:19:00 │   16.3 │               7.4 │\n│ 8c2a1008b82b5ff │ 2010-01-18 20:22:20 │ 2010-01-13 14:38:14 │   12.7 │ 8.199999999999998 │\n│ 8c2a100d65653ff │ 2010-01-09 01:18:00 │ 2010-01-14 09:26:00 │   14.3 │               5.4 │\n│ 8c2a100d22945ff │ 2010-01-18 19:10:14 │ 2010-01-28 18:43:52 │   6.67 │               7.0 │\n│ 8c2a10725ac5bff │ 2010-01-17 09:18:00 │ 2010-01-18 21:15:00 │    6.6 │               7.9 │\n│ 8c2a100d620b7ff │ 2010-01-09 13:49:00 │ 2010-01-16 00:08:00 │    7.4 │               5.5 │\n│ 8c2a1072c86abff │ 2010-01-09 00:25:00 │ 2010-01-01 08:23:30 │   12.3 │              12.6 │\n│ 8c2a100d2bb69ff │ 2010-01-27 18:15:00 │ 2010-01-20 15:07:00 │   12.0 │              13.0 │\n│ 8c2a107250403ff │ 2010-01-08 16:05:00 │ 2010-01-25 15:10:15 │   10.2 │              7.92 │\n│        ·        │          ·          │          ·          │     ·  │                ·  │\n│        ·        │          ·          │          ·          │     ·  │                ·  │\n│        ·        │          ·          │          ·          │     ·  │                ·  │\n│ 8c2a100d279d9ff │ 2010-01-14 04:14:00 │ 2010-01-27 06:02:00 │    8.3 │               8.0 │\n│ 8c2a100d29809ff │ 2010-01-25 21:58:00 │ 2010-01-16 14:14:00 │   13.9 │ 8.199999999999998 │\n│ 8c2a10725b28dff │ 2010-01-17 23:46:00 │ 2010-01-11 00:23:00 │    5.1 │ 8.599999999999998 │\n│ 8c2a100d2c85bff │ 2010-01-02 09:52:00 │ 2010-01-31 15:11:33 │    5.2 │             14.95 │\n│ 8c2a100d654abff │ 2010-01-27 22:29:00 │ 2010-01-28 22:00:46 │    7.5 │               8.3 │\n│ 8c2a100d3531dff │ 2010-01-21 12:55:00 │ 2010-01-31 15:47:00 │   11.4 │              12.9 │\n│ 8c2a10089649dff │ 2010-01-20 15:11:00 │ 2010-01-07 13:02:00 │   10.1 │               8.0 │\n│ 8c2a100d34965ff │ 2010-01-15 20:19:00 │ 2010-01-01 23:24:01 │    7.5 │               4.7 │\n│ 8c2a10774924bff │ 2010-01-16 20:11:00 │ 2010-01-30 03:14:04 │   13.1 │              11.9 │\n│ 8c2a100f34e99ff │ 2010-01-21 15:09:00 │ 2010-01-14 14:36:00 │   16.2 │               6.2 │\n├─────────────────┴─────────────────────┴─────────────────────┴────────┴───────────────────┤\n│ ? rows (&gt;9999 rows, 20 shown)                                                  5 columns │\n└──────────────────────────────────────────────────────────────────────────────────────────┘\n\n\n\n\nAvoiding Expensive Intermediates\nHowever, running count_rows on t2 forces the full join operation to be performed (previously, we only computed a partial join to dispaly the preview). The following takes about 50 seconds on my laptop.\nNote that the row count for this intermediate table is about 10 billion rows. We deal with the table directly here for demonstration purposes, but we as we continue the pipeline below, we will avoid ever forming this intermediate table.\n\n# renders slowly because you have to do the full join\nt2.do(count_rows)\n\n100% ▕████████████████████████████████████████████████████████████▏ \n\n\n┌──────────┐\n│ num_rows │\n│ varchar  │\n├──────────┤\n│ 1.05e+10 │\n└──────────┘\n\n\nAgain, it is intantaneous to form the expression representing t3, as long as we don’t need to compute the expression just yet.\nNote that the timestamp filtering below could have also been given above as part of the join. We’re free to do it either way and the performance will be identical because DuckDB will push the filters down in its query planning/optimization step.\n\nt3 = t2.do(\n    'where ts1 &lt; ts2',\n    'where ts2 &lt; ts1 + interval 1 minute',\n    'select hexid, max(abs(amt1-amt2)) as diff group by 1',\n    'where diff &gt; 0'\n    'order by diff',\n    'hide',\n)\n\nNote that this is faster than the t2.do(count_rows), even though it does more work! This cell runs in about 44 seconds on my laptop.\n\n\nMaterialize smaller results\nThis final result has about 29 thousand rows, something much more reasonable to materialize directly as a Pandas dataframe, for instance.\n\nt3.do(count_rows)\n\n100% ▕████████████████████████████████████████████████████████████▏ \n\n\n┌──────────┐\n│ num_rows │\n│ varchar  │\n├──────────┤\n│ 2.86e+04 │\n└──────────┘\n\n\nWe can translate to a Pandas dataframe in about 53 seconds.\n\nt3.df()\n\n100% ▕████████████████████████████████████████████████████████████▏ \n\n\n\n\n\n\n\n\n\nhexid\ndiff\n\n\n\n\n0\n8c2a100d2d12bff\n0.01\n\n\n1\n8c2a100d2a94dff\n0.02\n\n\n2\n8c2a100891611ff\n0.02\n\n\n3\n8c2a1072c846bff\n0.02\n\n\n4\n8c2a100d67a93ff\n0.02\n\n\n...\n...\n...\n\n\n28563\n8c2a10aa2cb13ff\n175.88\n\n\n28564\n8c2a100f52815ff\n180.45\n\n\n28565\n8c2a108f664e7ff\n203.00\n\n\n28566\n8c2a100d676d7ff\n212.37\n\n\n28567\n8c2a10d76aa37ff\n213.57\n\n\n\n\n28568 rows × 2 columns\n\n\n\n\n# TODO: get a polars dataframe",
    "crumbs": [
      "Tutorials",
      "Lazy Evaluation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Duckboat",
    "section": "",
    "text": "GitHub | Docs | PyPI\nUnsightly to some, but gets the job done.\nDuckboat is a SQL-based Python dataframe library for ergonomic interactive data analysis and exploration.\npip install duckboat\nDuckboat allows you to chain SQL snippets (meaning you can usually omit select * and from ...) to incrementally and lazily build up complex queries.\nDuckboat is a light wrapper around the DuckDB relational API, so expressions are evaluated lazily and optimized by DuckDB. The resulting queries are fast, avoiding the need to materialize intermediate tables or perform data transfers.\n\n\nimport duckboat as uck\n\ncsv = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\n\nuck.Table(csv).do(\n    \"where sex = 'female' \",\n    'where year &gt; 2008',\n    'select *, cast(body_mass_g as double) as grams',\n    'select species, island, avg(grams) as avg_grams group by 1,2',\n    'select * replace (round(avg_grams, 1) as avg_grams)',\n    'order by avg_grams',\n)\n┌───────────┬───────────┬───────────┐\n│  species  │  island   │ avg_grams │\n│  varchar  │  varchar  │  double   │\n├───────────┼───────────┼───────────┤\n│ Adelie    │ Torgersen │    3193.8 │\n│ Adelie    │ Dream     │    3357.5 │\n│ Adelie    │ Biscoe    │    3446.9 │\n│ Chinstrap │ Dream     │    3522.9 │\n│ Gentoo    │ Biscoe    │    4786.3 │\n└───────────┴───────────┴───────────┘\n\n\n\nThis approach results in a mixture of Python and SQL that, I think, is semantically very similar to Google’s Pipe Syntax for SQL: We can leverage our existing knowledge of SQL, while making a few small changes to make it more ergonomic and composable.\nWhen doing interactive data analysis, I find this approach easier to read and write than fluent APIs (like in Polars or Ibis) or typical Pandas code. If some operation is easier in other libraries, Duckboat makes it straightforward translate between them, either directly or through Apache Arrow.\n\n\n\nI’d love to hear any feedback on the approach here, so feel free to reach out through Issues or Discussions.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#example",
    "href": "index.html#example",
    "title": "Duckboat",
    "section": "",
    "text": "import duckboat as uck\n\ncsv = 'https://raw.githubusercontent.com/allisonhorst/palmerpenguins/main/inst/extdata/penguins.csv'\n\nuck.Table(csv).do(\n    \"where sex = 'female' \",\n    'where year &gt; 2008',\n    'select *, cast(body_mass_g as double) as grams',\n    'select species, island, avg(grams) as avg_grams group by 1,2',\n    'select * replace (round(avg_grams, 1) as avg_grams)',\n    'order by avg_grams',\n)\n┌───────────┬───────────┬───────────┐\n│  species  │  island   │ avg_grams │\n│  varchar  │  varchar  │  double   │\n├───────────┼───────────┼───────────┤\n│ Adelie    │ Torgersen │    3193.8 │\n│ Adelie    │ Dream     │    3357.5 │\n│ Adelie    │ Biscoe    │    3446.9 │\n│ Chinstrap │ Dream     │    3522.9 │\n│ Gentoo    │ Biscoe    │    4786.3 │\n└───────────┴───────────┴───────────┘",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#philosophy",
    "href": "index.html#philosophy",
    "title": "Duckboat",
    "section": "",
    "text": "This approach results in a mixture of Python and SQL that, I think, is semantically very similar to Google’s Pipe Syntax for SQL: We can leverage our existing knowledge of SQL, while making a few small changes to make it more ergonomic and composable.\nWhen doing interactive data analysis, I find this approach easier to read and write than fluent APIs (like in Polars or Ibis) or typical Pandas code. If some operation is easier in other libraries, Duckboat makes it straightforward translate between them, either directly or through Apache Arrow.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#feedback",
    "href": "index.html#feedback",
    "title": "Duckboat",
    "section": "",
    "text": "I’d love to hear any feedback on the approach here, so feel free to reach out through Issues or Discussions.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "concepts.html",
    "href": "concepts.html",
    "title": "Concepts",
    "section": "",
    "text": "import duckboat as uck\n\n# read from a remote CSV file\ntbl = uck.Table('https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/refs/heads/master/palmerpenguins/data/penguins.csv')\ntbl = uck.Table('data/penguins.csv')  # read from a local CSV file\n\ndf = tbl.df()  # write to Pandas DataFrame\nuck.Table(df)  # read from Pandas DataFrame\n\ndf.to_parquet('data/penguins.parquet')  # use Pandas to write to a Parquet file\ntbl = uck.Table('data/penguins.parquet')  # read from a local Parquet file\n\ntbl_arrow = tbl.arrow()  # write to an  Arrow Table\ntbl = uck.Table(tbl_arrow)  # read from an Arrow Table",
    "crumbs": [
      "Concepts"
    ]
  },
  {
    "objectID": "concepts.html#loading-saving-and-transferring-tables",
    "href": "concepts.html#loading-saving-and-transferring-tables",
    "title": "Concepts",
    "section": "",
    "text": "import duckboat as uck\n\n# read from a remote CSV file\ntbl = uck.Table('https://raw.githubusercontent.com/mcnakhaee/palmerpenguins/refs/heads/master/palmerpenguins/data/penguins.csv')\ntbl = uck.Table('data/penguins.csv')  # read from a local CSV file\n\ndf = tbl.df()  # write to Pandas DataFrame\nuck.Table(df)  # read from Pandas DataFrame\n\ndf.to_parquet('data/penguins.parquet')  # use Pandas to write to a Parquet file\ntbl = uck.Table('data/penguins.parquet')  # read from a local Parquet file\n\ntbl_arrow = tbl.arrow()  # write to an  Arrow Table\ntbl = uck.Table(tbl_arrow)  # read from an Arrow Table",
    "crumbs": [
      "Concepts"
    ]
  },
  {
    "objectID": "concepts.html#databases-and-tables",
    "href": "concepts.html#databases-and-tables",
    "title": "Concepts",
    "section": "Databases and Tables",
    "text": "Databases and Tables\nThe library revolves around two objects and a function: Database, Table.\n\nDatabase is essentially a dictionary mapping names to objects that will get resolved to tables. Those objects might be a Pandas or Polars dataframe, a PyArrow Table, the local filename of a Parquet or CSV file, or a URL to a remote data file. These objects are used by duckboat and Duckdb lazily, so operations on them are deffered until a final result is requested.\nTable is a wrapper around a DuckDB Relation.",
    "crumbs": [
      "Concepts"
    ]
  },
  {
    "objectID": "concepts.html#laziness",
    "href": "concepts.html#laziness",
    "title": "Concepts",
    "section": "Laziness",
    "text": "Laziness\nSince all operations are done through DuckDBPyRelation, the expressions are evaluated lazily, or only at the end when we want a table or want to display results to the console.\nIf you would like to materialze a Table or a Database concretely in terms of Pandas DataFrames or PyArrow Tables, you can use x.hold(kind='arrow') or x.do('arrow').\nWhen you materialize a Database you can access the underlying tables with db[table_name].",
    "crumbs": [
      "Concepts"
    ]
  },
  {
    "objectID": "concepts.html#examples",
    "href": "concepts.html#examples",
    "title": "Concepts",
    "section": "Examples",
    "text": "Examples\n\nChaining\nduckboat uses DuckDB to build up Relation expressions through chaining, which DuckDB will then execute after running the entire expression through a query planner to optimize execution.\nimport duckboat as uck\n\n# uck.Table('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet')\nuck.Table('yellow_tripdata_2010-01.parquet').do(\n    'select *, pickup_latitude as lat, pickup_longitude as lng',\n    'select *, h3_latlng_to_cell(lat, lng, 8) as hexid',\n    'select hexid, avg(tip_amount) as tip  group by 1',\n    'select h3_h3_to_string(hexid) as hexid, tip',\n    'where tip between 10 and 20',\n    'order by hexid',\n)\nGives the output:\n┌─────────────────┬────────────────────┐\n│      hexid      │        tip         │\n│     varchar     │       double       │\n├─────────────────┼────────────────────┤\n│ 881bb2a0b5fffff │              12.22 │\n│ 882a100299fffff │  10.02818181818182 │\n│ 882a10029dfffff │ 11.666666666666666 │\n│ 882a1002c3fffff │               10.0 │\n│ 882a10034bfffff │               16.0 │\n│ 882a100353fffff │               17.6 │\n│ 882a10045bfffff │               10.0 │\n│ 882a100487fffff │             11.525 │\n│ 882a10060dfffff │               16.1 │\n│ 882a100611fffff │               10.0 │\n│        ·        │                 ·  │\n│        ·        │                 ·  │\n│        ·        │                 ·  │\n│ 882a13c4d9fffff │               11.5 │\n│ 882a13d281fffff │               20.0 │\n│ 882a13d529fffff │               15.0 │\n│ 882a1438c3fffff │               10.0 │\n│ 882a15663bfffff │               10.0 │\n│ 882a1ab9c1fffff │              10.01 │\n│ 882a353927fffff │              11.05 │\n│ 882aa16327fffff │              12.51 │\n│ 882aaab9ebfffff │              10.01 │\n│ 882ad09327fffff │              12.51 │\n├─────────────────┴────────────────────┤\n│ 193 rows (20 shown)        2 columns │\n└──────────────────────────────────────┘\n\nAlternatives\nYou can also write the above as\nuck.Table('data/yellow_tripdata_2010-01.parquet').do(\n    'select *, pickup_latitude as lat, pickup_longitude as lng',\n    'select *, h3_latlng_to_cell(lat, lng, 8) as hexid',\n    'select hexid, avg(tip_amount) as tip  group by 1',\n    'select h3_h3_to_string(hexid) as hexid, tip',\n    'where tip between 10 and 20',\n    'order by hexid',\n)\nor\nuck.Table('data/yellow_tripdata_2010-01.parquet').do(\n    'select *, pickup_latitude as lat, pickup_longitude as lng',\n).do(\n    'select *, h3_latlng_to_cell(lat, lng, 8) as hexid',\n).do(\n    'select hexid, avg(tip_amount) as tip  group by 1',\n).do(\n    'select h3_h3_to_string(hexid) as hexid, tip',\n).do(\n   'where tip between 10 and 20',\n).do(\n    'order by hexid',\n)\n\n\n\nPivot\nTODO\n\n\nStoring procedures\nYou might store a sequence of steps as a function like\ndef foo(rel, res=6):\n    return (rel\n    | 'select pickup_latitude as lat, pickup_longitude as lng, tip_amount'       \n    | f'select h3_latlng_to_cell(lat, lng, {res}) as hexid, tip_amount as tip'\n    | 'select hexid, avg(tip) as tip group by 1'\n    | 'select h3_h3_to_string(hexid) as hexid, tip'\n    | 'where tip &gt; 0'\n    )\nwhich you could apply with any of the following syntax:\n\ntable.do(foo)\ntable | foo or table &gt;&gt; foo\n\nAlternatively, you could store this as a sequence of strings:\nfoo_list = [\n    'select pickup_latitude as lat, pickup_longitude as lng, tip_amount'       \n    'select h3_latlng_to_cell(lat, lng, 6}) as hexid, tip_amount as tip'\n    'select hexid, avg(tip) as tip group by 1'\n    'select h3_h3_to_string(hexid) as hexid, tip'\n    'where tip &gt; 0'\n]\nwhich you could apply with something like\ntable.do(*foo_list)\nor\ntable.do(foo_list)\nor even\ntable | foo_list",
    "crumbs": [
      "Concepts"
    ]
  },
  {
    "objectID": "tut_nyc_join.html",
    "href": "tut_nyc_join.html",
    "title": "NYC Trips Example Analysis",
    "section": "",
    "text": "We’ll use the NYC Taxi data set to demonstrate analyzing data interactively with Duckboat. We’ll compare Taxi trip fares by pickup location between January and February 2010.\nWe discretize locations into hexagonal bins with H3. One of the benefits of using DuckDB directly, is that we can use anything from the DuckDB ecosystem, like its H3 extension.\n\nLoading data\nFirst, load a table from a local Parquet file and preview its contents.\n\nimport duckboat as uck\nt1 = uck.Table('data/yellow_tripdata_2010-01.parquet')\nt2 = uck.Table('data/yellow_tripdata_2010-02.parquet')\nt1.do('limit 7')\n\n┌───────────┬─────────────────────┬─────────────────────┬─────────────────┬────────────────────┬────────────────────┬─────────────────┬───────────┬────────────────────┬────────────────────┬──────────────────┬──────────────┬─────────────┬───────────┬─────────┬────────────┬──────────────┬──────────────┐\n│ vendor_id │   pickup_datetime   │  dropoff_datetime   │ passenger_count │   trip_distance    │  pickup_longitude  │ pickup_latitude │ rate_code │ store_and_fwd_flag │ dropoff_longitude  │ dropoff_latitude │ payment_type │ fare_amount │ surcharge │ mta_tax │ tip_amount │ tolls_amount │ total_amount │\n│  varchar  │       varchar       │       varchar       │      int64      │       double       │       double       │     double      │  varchar  │      varchar       │       double       │      double      │   varchar    │   double    │  double   │ double  │   double   │    double    │    double    │\n├───────────┼─────────────────────┼─────────────────────┼─────────────────┼────────────────────┼────────────────────┼─────────────────┼───────────┼────────────────────┼────────────────────┼──────────────────┼──────────────┼─────────────┼───────────┼─────────┼────────────┼──────────────┼──────────────┤\n│ VTS       │ 2010-01-26 07:41:00 │ 2010-01-26 07:45:00 │               1 │               0.75 │         -73.956778 │        40.76775 │ 1         │ NULL               │         -73.965957 │        40.765232 │ CAS          │         4.5 │       0.0 │     0.5 │        0.0 │          0.0 │          5.0 │\n│ DDS       │ 2010-01-30 23:31:00 │ 2010-01-30 23:46:12 │               1 │                5.9 │ -73.99611799999998 │       40.763932 │ 1         │ NULL               │ -73.98151199999998 │        40.741193 │ CAS          │        15.3 │       0.5 │     0.5 │        0.0 │          0.0 │         16.3 │\n│ DDS       │ 2010-01-18 20:22:20 │ 2010-01-18 20:38:12 │               1 │                4.0 │         -73.979673 │        40.78379 │ 1         │ NULL               │ -73.91785199999998 │         40.87856 │ CAS          │        11.7 │       0.5 │     0.5 │        0.0 │          0.0 │         12.7 │\n│ VTS       │ 2010-01-09 01:18:00 │ 2010-01-09 01:35:00 │               2 │                4.7 │         -73.977922 │       40.763997 │ 1         │ NULL               │ -73.92390799999998 │        40.759725 │ CAS          │        13.3 │       0.5 │     0.5 │        0.0 │          0.0 │         14.3 │\n│ CMT       │ 2010-01-18 19:10:14 │ 2010-01-18 19:17:07 │               1 │ 0.5999999999999999 │         -73.990924 │       40.734682 │ 1         │ 0                  │ -73.99551099999998 │        40.739088 │ Cre          │         5.3 │       0.0 │     0.5 │       0.87 │          0.0 │         6.67 │\n│ DDS       │ 2010-01-23 18:40:25 │ 2010-01-23 18:54:51 │               1 │                3.3 │                0.0 │             0.0 │ 1         │ NULL               │                0.0 │              0.0 │ CRE          │        10.5 │       0.0 │     0.5 │        1.0 │          0.0 │         12.0 │\n│ VTS       │ 2010-01-17 09:18:00 │ 2010-01-17 09:25:00 │               1 │               1.33 │         -73.993747 │       40.754917 │ 1         │ NULL               │ -73.98471499999998 │        40.755927 │ CAS          │         6.1 │       0.0 │     0.5 │        0.0 │          0.0 │          6.6 │\n└───────────┴─────────────────────┴─────────────────────┴─────────────────┴────────────────────┴────────────────────┴─────────────────┴───────────┴────────────────────┴────────────────────┴──────────────────┴──────────────┴─────────────┴───────────┴─────────┴────────────┴──────────────┴──────────────┘\n\n\nWe can get a list of columns with t1.columns.\n\nt1.columns\n\n['vendor_id',\n 'pickup_datetime',\n 'dropoff_datetime',\n 'passenger_count',\n 'trip_distance',\n 'pickup_longitude',\n 'pickup_latitude',\n 'rate_code',\n 'store_and_fwd_flag',\n 'dropoff_longitude',\n 'dropoff_latitude',\n 'payment_type',\n 'fare_amount',\n 'surcharge',\n 'mta_tax',\n 'tip_amount',\n 'tolls_amount',\n 'total_amount']\n\n\n\n\nInspecting and transforming data interactively\nYou can run one or more SQL expressions with the Table.do() method.\nExpressions are in standard DuckDB SQL, with some small changes:\n\nfrom &lt;table_name&gt; is automatically inserted into the expression for you.\nselect ... is optional; if omitted, select * will be inserted.\n\nWe’ll see a few examples of what we can do below.\nConvert pickup latitude/longitude locations to resolution 8 H3 cells. Resolution 8 cells are about 0.7 km^2 in size.\n\nx = t1.do(\"\"\"\nselect\n    *,\n    h3_latlng_to_cell(pickup_latitude, pickup_longitude, 8)\n        as hexid,\n\"\"\")\nx.do('limit 2')\n\n┌───────────┬─────────────────────┬─────────────────────┬─────────────────┬───────────────┬────────────────────┬─────────────────┬───────────┬────────────────────┬────────────────────┬──────────────────┬──────────────┬─────────────┬───────────┬─────────┬────────────┬──────────────┬──────────────┬────────────────────┐\n│ vendor_id │   pickup_datetime   │  dropoff_datetime   │ passenger_count │ trip_distance │  pickup_longitude  │ pickup_latitude │ rate_code │ store_and_fwd_flag │ dropoff_longitude  │ dropoff_latitude │ payment_type │ fare_amount │ surcharge │ mta_tax │ tip_amount │ tolls_amount │ total_amount │       hexid        │\n│  varchar  │       varchar       │       varchar       │      int64      │    double     │       double       │     double      │  varchar  │      varchar       │       double       │      double      │   varchar    │   double    │  double   │ double  │   double   │    double    │    double    │       uint64       │\n├───────────┼─────────────────────┼─────────────────────┼─────────────────┼───────────────┼────────────────────┼─────────────────┼───────────┼────────────────────┼────────────────────┼──────────────────┼──────────────┼─────────────┼───────────┼─────────┼────────────┼──────────────┼──────────────┼────────────────────┤\n│ VTS       │ 2010-01-26 07:41:00 │ 2010-01-26 07:45:00 │               1 │          0.75 │         -73.956778 │        40.76775 │ 1         │ NULL               │         -73.965957 │        40.765232 │ CAS          │         4.5 │       0.0 │     0.5 │        0.0 │          0.0 │          5.0 │ 613229522950553599 │\n│ DDS       │ 2010-01-30 23:31:00 │ 2010-01-30 23:46:12 │               1 │           5.9 │ -73.99611799999998 │       40.763932 │ 1         │ NULL               │ -73.98151199999998 │        40.741193 │ CAS          │        15.3 │       0.5 │     0.5 │        0.0 │          0.0 │         16.3 │ 613229551343894527 │\n└───────────┴─────────────────────┴─────────────────────┴─────────────────┴───────────────┴────────────────────┴─────────────────┴───────────┴────────────────────┴────────────────────┴──────────────────┴──────────────┴─────────────┴───────────┴─────────┴────────────┴──────────────┴──────────────┴────────────────────┘\n\n\nCompute the average of total_amount for each H3 cell, along with the number of trips:\n\nx = x.do(\"\"\"\nselect\n    hexid,\n    avg(total_amount) \n        as amount,\n    count(*)\n        as num,\ngroup by\n    1\n\"\"\")\nx.do('limit 2')\n\n┌────────────────────┬────────────────────┬────────┐\n│       hexid        │       amount       │  num   │\n│       uint64       │       double       │ int64  │\n├────────────────────┼────────────────────┼────────┤\n│ 613229522984108031 │  9.949875167611044 │ 346785 │\n│ 613229551278882815 │ 10.650209316209912 │ 308194 │\n└────────────────────┴────────────────────┴────────┘\n\n\nConvert the H3 cell id to its hexadecimal representation:\n\nx = x.do(\"\"\"\nselect\n    h3_h3_to_string(hexid)\n        as hexid,\n    amount,\n    num,\n\"\"\")\nx.do('limit 2')\n\n┌─────────────────┬────────────────────┬────────┐\n│      hexid      │       amount       │  num   │\n│     varchar     │       double       │ int64  │\n├─────────────────┼────────────────────┼────────┤\n│ 882a1008bbfffff │  9.670524807010343 │ 288487 │\n│ 882a100d65fffff │ 10.816309067189671 │ 666127 │\n└─────────────────┴────────────────────┴────────┘\n\n\n\n\nGrouping transforms with lists and functions\nNote that Table.do() also accepts a sequence of strings, so you could write all of the previous steps with a single function call.\n\nt1.do(\n    'select *, h3_latlng_to_cell(pickup_latitude, pickup_longitude, 8) as hexid',\n    'select hexid, avg(total_amount) as amount, count(*) as num group by 1',\n    'select h3_h3_to_string(hexid) as hexid, amount, num',\n    'limit 5'\n)\n\n┌─────────────────┬────────────────────┬────────┐\n│      hexid      │       amount       │  num   │\n│     varchar     │       double       │ int64  │\n├─────────────────┼────────────────────┼────────┤\n│ 882a1008bbfffff │   9.67052480701034 │ 288487 │\n│ 882a100d65fffff │  10.81630906718967 │ 666127 │\n│ 882a100f57fffff │ 28.707747238240923 │  71965 │\n│ 882a100da5fffff │   12.8694763361526 │  11114 │\n│ 882a100d45fffff │ 10.594611812368372 │ 185619 │\n└─────────────────┴────────────────────┴────────┘\n\n\nTo help organize things, we can collect a sequence of steps as a list of strings.\n\navg_list = [\n    'select *, h3_latlng_to_cell(pickup_latitude, pickup_longitude, 8) as hexid',\n    'select hexid, avg(total_amount) as amount, count(*) as num group by 1',\n    'select h3_h3_to_string(hexid) as hexid, amount, num',\n]\n\nWe can apply the sequence of steps in avg_list to table t1 in multiple ways. If Table.do() encounters a list, it will apply each element of the list in sequence recursively, which means each of the following are equivalent:\n\nt1.do(*avg_list)\nt1.do(avg_list)\nt1.do([avg_list])\nt1.do([[avg_list]])\n\nWe can also wrap operations in a Python function, which Table.do() can also handle.\n\ndef avg_func(tbl):\n    \"\"\"\n    tbl: [pickup_latitude, pickup_longitude, total_amount]\n    returns: [hexid, amount, num]\n    \"\"\"\n    return tbl.do(avg_list)\n\nThe following are equivalent:\n\navg_func(t1)\nt1.do(avg_func)\nt1.do([avg_func])\n\nWe can build up complex nested expressions by combining functions, query strings, and lists, so the following are equivalent:\n\nt1.do(avg_func, 'where num &gt; 100')\nt1.do(avg_list, 'where num &gt; 100')\nt1.do([avg_func, 'where num &gt; 100'])\nt1.do([avg_list, 'where num &gt; 100'])\n\n\n\nExploration and filtering\nExploring the data, we notice there are many trips in February that have zero or negative fare. We’ll want to filter those out.\n\nt2.do(\"\"\"\nselect\n    total_amount &gt; 0,\n    count(*),\ngroup by\n    1\n\"\"\")\n\n┌────────────────────┬──────────────┐\n│ (total_amount &gt; 0) │ count_star() │\n│      boolean       │    int64     │\n├────────────────────┼──────────────┤\n│ true               │     11133961 │\n│ false              │        11448 │\n└────────────────────┴──────────────┘\n\n\nWe also spot many trips where the lat/lng is erroneously listed as (0,0):\n\nt1.do(\"\"\"\nselect\n    (pickup_longitude = 0) or (pickup_latitude = 0),\n    count(*),\ngroup by\n    1\n\"\"\")\n\n┌───────────────────────────────────────────────────┬──────────────┐\n│ ((pickup_longitude = 0) OR (pickup_latitude = 0)) │ count_star() │\n│                      boolean                      │    int64     │\n├───────────────────────────────────────────────────┼──────────────┤\n│ true                                              │       268338 │\n│ false                                             │     14595440 │\n└───────────────────────────────────────────────────┴──────────────┘\n\n\nAfter aggregating, we also notice there are lots of hexes with only a few trips. Let’s say we’ll only look at hexes with at least 100 trips.\n\nt1.do(\n    avg_func,\n    \"\"\"\n    select\n        cast(log10(num)+1 as int)\n            as num_digits,\n        count(*),\n    group by 1\n    order by 1\n    \"\"\"\n)\n\n┌────────────┬──────────────┐\n│ num_digits │ count_star() │\n│   int32    │    int64     │\n├────────────┼──────────────┤\n│          1 │         5907 │\n│          2 │         1784 │\n│          3 │          619 │\n│          4 │          165 │\n│          5 │           58 │\n│          6 │           43 │\n│          7 │           18 │\n└────────────┴──────────────┘\n\n\n\n\nJoins\nWe want to compute average fares for hexes and compare them across January and February. We compute the averages like above, but also want to exlude hexes with only a few trips. So we extend the data pipeline to filter out such hexes, and apply the same operation to the datasets for each month.\n\nt1 = uck.Table('data/yellow_tripdata_2010-01.parquet')\nt2 = uck.Table('data/yellow_tripdata_2010-02.parquet')\n\nf = [\n    'where (pickup_longitude != 0) and (pickup_latitude != 0)',\n    'where total_amount &gt; 0',\n    avg_list,\n    'where num &gt; 100',\n]\n\nt1 = t1.do(f)\nt2 = t2.do(f)\n\nt2\n\n┌─────────────────┬────────────────────┬────────┐\n│      hexid      │       amount       │  num   │\n│     varchar     │       double       │ int64  │\n├─────────────────┼────────────────────┼────────┤\n│ 882a100dc5fffff │ 12.866180392156863 │   1275 │\n│ 882a1072c1fffff │ 10.879886217377141 │ 257948 │\n│ 882a1072cdfffff │ 10.630242212783157 │ 276864 │\n│ 882a100d23fffff │  9.907107156892392 │ 310442 │\n│ 882a100d43fffff │ 11.572584972355664 │  11033 │\n│ 882a107289fffff │ 13.817384161180893 │ 125325 │\n│ 882a100d69fffff │  9.002230887441275 │ 313001 │\n│ 882a100d2bfffff │  9.804291920508977 │ 177932 │\n│ 882a103b39fffff │ 49.016554389839804 │   1811 │\n│ 882a1008cbfffff │  10.79668774319066 │   4112 │\n│        ·        │          ·         │     ·  │\n│        ·        │          ·         │     ·  │\n│        ·        │          ·         │     ·  │\n│ 882a100ab9fffff │  11.28739644970414 │    338 │\n│ 882a100a87fffff │  13.15985111662531 │    403 │\n│ 882a100a19fffff │ 12.468518518518518 │    135 │\n│ 882a107441fffff │ 11.984125874125876 │    143 │\n│ 88754e6499fffff │ 11.673359374999999 │    128 │\n│ 882a107401fffff │  9.635284552845528 │    123 │\n│ 882a100db9fffff │ 12.123602150537634 │    186 │\n│ 882a100e15fffff │ 13.394957983193278 │    119 │\n│ 882a10704bfffff │ 17.155999999999995 │    115 │\n│ 882a100d95fffff │ 14.229345794392524 │    107 │\n├─────────────────┴────────────────────┴────────┤\n│ 444 rows (20 shown)                 3 columns │\n└───────────────────────────────────────────────┘\n\n\nTo perform a join, we need two tables in hand, which we can do with duckboat.Database():\n\ndb = uck.Database(t1=t1, t2=t2)\n\n\ndb['t1']\n\n┌─────────────────┬────────────────────┬────────┐\n│      hexid      │       amount       │  num   │\n│     varchar     │       double       │ int64  │\n├─────────────────┼────────────────────┼────────┤\n│ 882a1072c9fffff │ 10.324864870461472 │ 386333 │\n│ 882a100883fffff │  9.985855459480877 │ 222512 │\n│ 882a10089bfffff │  10.68603411867983 │ 252882 │\n│ 882a10725bfffff │ 10.288604039526435 │ 421287 │\n│ 882a107281fffff │ 14.549411366436937 │  73849 │\n│ 882a100893fffff │   9.66153303243029 │ 426051 │\n│ 882a1072c3fffff │  11.38762527914247 │  89560 │\n│ 882a1008d9fffff │  11.12186782282635 │  12801 │\n│ 882a100899fffff │ 10.312122802937248 │ 210679 │\n│ 882a100ab7fffff │  12.24510952168082 │   4474 │\n│        ·        │          ·         │     ·  │\n│        ·        │          ·         │     ·  │\n│        ·        │          ·         │     ·  │\n│ 882a103b09fffff │ 22.962156862745097 │    153 │\n│ 882a107769fffff │ 15.806824644549764 │    211 │\n│ 882a100aedfffff │  13.59441340782123 │    179 │\n│ 882a10775bfffff │ 12.418489795918367 │    245 │\n│ 882a10723dfffff │ 17.827465753424658 │    146 │\n│ 882a100813fffff │ 16.437430167597764 │    179 │\n│ 882a100129fffff │ 13.823333333333332 │    111 │\n│ 882a100e3dfffff │  13.37867924528302 │    106 │\n│ 882a10705bfffff │ 25.104952830188676 │    212 │\n│ 882a100f47fffff │ 10.159645390070922 │    141 │\n├─────────────────┴────────────────────┴────────┤\n│ 504 rows (20 shown)                 3 columns │\n└───────────────────────────────────────────────┘\n\n\nNote that because evaluation is lazy, the expressions to build each table in the database will recompute each time you compute or view a derived expression. If you want to avoid that, you can materialize the computation and create a new database. There is no need to do this if you don’t mind recomputing.\n\ndb = uck.Database(**db.hold())\n\n\ndb\n\nDatabase:\n    t1: 504 x ['hexid', 'amount', 'num']\n    t2: 444 x ['hexid', 'amount', 'num']\n\n\nThe following will run quickly.\n\ndb.do('from t1')\n\n┌─────────────────┬────────────────────┬────────┐\n│      hexid      │       amount       │  num   │\n│     varchar     │       double       │ int64  │\n├─────────────────┼────────────────────┼────────┤\n│ 882a107219fffff │ 10.439549116797137 │ 104506 │\n│ 882a100d4dfffff │  10.47793938201142 │  71134 │\n│ 882a1008b3fffff │  9.949875167611046 │ 346785 │\n│ 882a10721bfffff │ 10.650209316209915 │ 308194 │\n│ 882a103b1dfffff │ 39.663308764407496 │  59696 │\n│ 882a100d6dfffff │  9.794619010597282 │ 142773 │\n│ 882a1008d3fffff │ 10.761599008147348 │  28230 │\n│ 882a1072ddfffff │ 11.091350516373895 │  22658 │\n│ 882a100895fffff │   9.83854816036588 │ 106706 │\n│ 882a107447fffff │  10.89207468879668 │    482 │\n│        ·        │          ·         │     ·  │\n│        ·        │          ·         │     ·  │\n│        ·        │          ·         │     ·  │\n│ 882a100e31fffff │ 27.070084745762717 │    236 │\n│ 882a100ac7fffff │ 10.728798283261805 │    233 │\n│ 882a100aa5fffff │ 10.468103448275864 │    116 │\n│ 882a100d95fffff │ 15.551118421052632 │    152 │\n│ 882a1071a5fffff │ 17.261560283687945 │    141 │\n│ 882a100e8bfffff │ 14.027241379310343 │    145 │\n│ 882a10704bfffff │  17.15892857142857 │    168 │\n│ 882a100a19fffff │ 14.915785714285715 │    140 │\n│ 882a106363fffff │ 10.539056603773586 │    106 │\n│ 882a100e15fffff │ 10.808161764705883 │    136 │\n├─────────────────┴────────────────────┴────────┤\n│ 504 rows (20 shown)                 3 columns │\n└───────────────────────────────────────────────┘\n\n\nYou can run DuckDB SQL on a duckboat.Database, but now you should explicitly mention the table(s) you want to work with (but that’s usually what you want anyway when doing a join.)\n\nout = db.do(\"\"\"\nselect\n      hexid\n    , t1.amount\n        as fare_jan\n    , t2.amount\n        as fare_feb\nfrom\n    t1\ninner join\n    t2\nusing\n    (hexid)\n\"\"\").do(\"\"\"\nselect\n      *\n    , fare_feb - fare_jan\n        as fare_change\norder by\n    fare_change\n\"\"\")\nout\n\n┌─────────────────┬────────────────────┬────────────────────┬─────────────────────┐\n│      hexid      │      fare_jan      │      fare_feb      │     fare_change     │\n│     varchar     │       double       │       double       │       double        │\n├─────────────────┼────────────────────┼────────────────────┼─────────────────────┤\n│ 882a1071adfffff │  69.73084615384616 │ 58.737914798206276 │ -10.992931355639882 │\n│ 882a100c01fffff │ 27.110503597122307 │ 20.741372549019605 │  -6.369131048102702 │\n│ 882a100e37fffff │  33.03063551401869 │  28.06555765595463 │   -4.96507785806406 │\n│ 882a1072e7fffff │ 42.255209580838326 │  38.42423076923077 │  -3.830978811607558 │\n│ 882a1008e9fffff │ 17.742466666666665 │        14.00984375 │ -3.7326229166666653 │\n│ 882a1008e7fffff │ 14.852932330827068 │ 11.121284403669724 │ -3.7316479271573435 │\n│ 882a107207fffff │ 16.860051282051284 │ 13.165116279069768 │ -3.6949350029815164 │\n│ 882a100e85fffff │ 29.665849999999992 │  26.64545454545455 │   -3.02039545454544 │\n│ 882a100cc1fffff │  18.81431818181818 │  15.84008695652174 │ -2.9742312252964407 │\n│ 882a10705bfffff │  25.10495283018868 │ 22.228385650224215 │ -2.8765671799644643 │\n│        ·        │          ·         │          ·         │            ·        │\n│        ·        │          ·         │          ·         │            ·        │\n│        ·        │          ·         │          ·         │            ·        │\n│ 882a10723bfffff │ 36.692529989094886 │ 42.577538896746816 │    5.88500890765193 │\n│ 882a1072e3fffff │  22.58889967637541 │ 28.593956521739123 │   6.005056845363715 │\n│ 882a107239fffff │ 30.491762376237624 │   36.8459880239521 │   6.354225647714479 │\n│ 882a107231fffff │  25.71543147208122 │  33.13404255319149 │   7.418611081110271 │\n│ 882a103b61fffff │   38.6792192513369 │  46.58243243243244 │   7.903213181095538 │\n│ 882a100ee5fffff │ 13.650664869721473 │ 21.770178571428573 │     8.1195137017071 │\n│ 882a107209fffff │ 16.478663594470046 │ 24.767259036144576 │    8.28859544167453 │\n│ 882a100813fffff │ 16.437430167597768 │  25.61198275862069 │   9.174552591022923 │\n│ 882a100d03fffff │ 12.004190371991243 │ 21.602025227750527 │   9.597834855759285 │\n│ 882a100ebbfffff │  39.36631964809386 │  53.30473029045644 │  13.938410642362584 │\n├─────────────────┴────────────────────┴────────────────────┴─────────────────────┤\n│ 426 rows (20 shown)                                                   4 columns │\n└─────────────────────────────────────────────────────────────────────────────────┘\n\n\n\nimport matplotlib.pyplot as plt\n\ndf = out.df()\n\nfig, ax = plt.subplots()\nax.plot([0,70], [0,70], color='k', linestyle='--')\ndf.plot.scatter(x='fare_jan', y='fare_feb', alpha=.6, ax=ax)\nplt.grid()\n\n\n\n\n\n\n\n\n\n\nEnd-to-end example\n\nimport duckboat as uck\n\ncore = [\n    'select *, h3_latlng_to_cell(pickup_latitude, pickup_longitude, 8) as hexid',\n    'select hexid, avg(total_amount) as amount, count(*) as num group by 1',\n    'select h3_h3_to_string(hexid) as hexid, amount, num',\n]\n\ncore_with_filters = [\n    'where (pickup_longitude != 0) and (pickup_latitude != 0)',\n    'where total_amount &gt; 0',\n    core,\n    'where num &gt; 100',\n]\n\ndb = uck.Database(\n    t1 = uck.Table('data/yellow_tripdata_2010-01.parquet').do(core_with_filters),\n    t2 = uck.Table('data/yellow_tripdata_2010-02.parquet').do(core_with_filters),\n)\n\ndb.do(\"\"\"\n    select\n        hexid,\n        t1.amount  as  fare_jan,\n        t2.amount  as  fare_feb,\n    from        t1\n    inner join  t2\n    using       (hexid)\n\"\"\",\n    'select *, fare_feb - fare_jan as fare_change',\n    'order by fare_change',\n)\n\n┌─────────────────┬────────────────────┬────────────────────┬─────────────────────┐\n│      hexid      │      fare_jan      │      fare_feb      │     fare_change     │\n│     varchar     │       double       │       double       │       double        │\n├─────────────────┼────────────────────┼────────────────────┼─────────────────────┤\n│ 882a1071adfffff │  69.73084615384616 │  58.73791479820627 │  -10.99293135563989 │\n│ 882a100c01fffff │ 27.110503597122303 │  20.74137254901961 │  -6.369131048102695 │\n│ 882a100e37fffff │   33.0306355140187 │  28.06555765595463 │  -4.965077858064067 │\n│ 882a1072e7fffff │  42.25520958083832 │  38.42423076923076 │  -3.830978811607558 │\n│ 882a1008e9fffff │ 17.742466666666665 │        14.00984375 │ -3.7326229166666653 │\n│ 882a1008e7fffff │ 14.852932330827068 │ 11.121284403669724 │ -3.7316479271573435 │\n│ 882a107207fffff │  16.86005128205128 │ 13.165116279069768 │  -3.694935002981513 │\n│ 882a100e85fffff │ 29.665849999999995 │ 26.645454545454545 │ -3.0203954545454508 │\n│ 882a100cc1fffff │ 18.814318181818177 │  15.84008695652174 │  -2.974231225296437 │\n│ 882a10705bfffff │  25.10495283018868 │ 22.228385650224215 │ -2.8765671799644643 │\n│        ·        │          ·         │          ·         │           ·         │\n│        ·        │          ·         │          ·         │           ·         │\n│        ·        │          ·         │          ·         │           ·         │\n│ 882a10723bfffff │  36.69252998909488 │ 42.577538896746816 │   5.885008907651937 │\n│ 882a1072e3fffff │ 22.588899676375405 │ 28.593956521739123 │   6.005056845363718 │\n│ 882a107239fffff │ 30.491762376237624 │   36.8459880239521 │   6.354225647714479 │\n│ 882a107231fffff │ 25.715431472081217 │ 33.134042553191485 │   7.418611081110267 │\n│ 882a103b61fffff │   38.6792192513369 │  46.58243243243243 │  7.9032131810955235 │\n│ 882a100ee5fffff │ 13.650664869721473 │  21.77017857142857 │   8.119513701707097 │\n│ 882a107209fffff │ 16.478663594470046 │ 24.767259036144583 │   8.288595441674538 │\n│ 882a100813fffff │ 16.437430167597768 │ 25.611982758620687 │    9.17455259102292 │\n│ 882a100d03fffff │ 12.004190371991243 │ 21.602025227750524 │   9.597834855759281 │\n│ 882a100ebbfffff │  39.36631964809386 │  53.30473029045643 │  13.938410642362577 │\n├─────────────────┴────────────────────┴────────────────────┴─────────────────────┤\n│ 426 rows (20 shown)                                                   4 columns │\n└─────────────────────────────────────────────────────────────────────────────────┘",
    "crumbs": [
      "Tutorials",
      "NYC Trips Join"
    ]
  },
  {
    "objectID": "duckdb_stuff.html",
    "href": "duckdb_stuff.html",
    "title": "DuckDB Concepts",
    "section": "",
    "text": "duckboat is primarily built on DuckDB’s Relational API. As an escape hatch, duckboat exposes its DuckDB compoents for you to use directly:",
    "crumbs": [
      "DuckDB Concepts"
    ]
  },
  {
    "objectID": "duckdb_stuff.html#whats-different-from-duckdbs-relational-api",
    "href": "duckdb_stuff.html#whats-different-from-duckdbs-relational-api",
    "title": "DuckDB Concepts",
    "section": "What’s different from DuckDB’s relational api",
    "text": "What’s different from DuckDB’s relational api\n\navoid connection objects",
    "crumbs": [
      "DuckDB Concepts"
    ]
  },
  {
    "objectID": "todo.html",
    "href": "todo.html",
    "title": "TODO",
    "section": "",
    "text": "function for loading data with remote\nidea:\nuck.Table(\n    'data/yellow_tripdata_2010-01.parquet',\n    remote='https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n)\ntry looking for file data/yellow_tripdata_2010-01.parquet. If no file exists, look at the remote, download the file, save it as the given filename, and then load from the given filename.\nTODO: can we also allow for mixing in pandas/polars/ibis code? maybe a function wrapper? That would be crazy powerful!\n\nas or alias?",
    "crumbs": [
      "Development",
      "TODO"
    ]
  },
  {
    "objectID": "tut_fsq.html",
    "href": "tut_fsq.html",
    "title": "Foursquare POI Data Example",
    "section": "",
    "text": "Foursquare has recently released an interesting Point of Interest (POI) Dataset, which is what we will play with in this example.\nFused.io has made that data readily available, through Source Cooperative which is how we will access it.\nimport duckboat as uck",
    "crumbs": [
      "Tutorials",
      "Foursquare POI"
    ]
  },
  {
    "objectID": "tut_fsq.html#load-the-data",
    "href": "tut_fsq.html#load-the-data",
    "title": "Foursquare POI Data Example",
    "section": "Load the data",
    "text": "Load the data\nWe can download the data with duckboat and save it to a file for quick iteration.\n\n# NOTE: You can comment out the following two lines once\n# you have the data saved locally to avoid downloading it again\nt = uck.Table('s3://us-west-2.opendata.source.coop/fused/fsq-os-places/2024-12-03/places/10.parquet').hide()\nt.save('data/fsq_places_10.parquet')\n\n100% ▕████████████████████████████████████████████████████████████▏ \n\n\nWith the data saved to a file, we can create a duckboat table from a local Parquet file.\n\nt = uck.Table('data/fsq_places_10.parquet')",
    "crumbs": [
      "Tutorials",
      "Foursquare POI"
    ]
  },
  {
    "objectID": "tut_fsq.html#data-processing",
    "href": "tut_fsq.html#data-processing",
    "title": "Foursquare POI Data Example",
    "section": "Data processing",
    "text": "Data processing\nAs noted elsewhere in the docs, we can store data operations in multiple ways. For example, as Python functions or as a list of SQL snippet strings. Here are some examples.\n\n# Collect an operation as a sequence of SQL snippets,\n# and parameterize the target H3 resolution.\ndef latlng_h3(res):\n    return [\n        f'select h3_latlng_to_cell(latitude, longitude, {res}) as hexid',\n        'select h3_h3_to_string(hexid) as hexid',\n    ]\n\n# A data processing procedure stored as a list of SQL snippet strings\ncount_and_order = [\n    'select hexid, count(*) as num group by 1',\n    'order by num',\n]",
    "crumbs": [
      "Tutorials",
      "Foursquare POI"
    ]
  },
  {
    "objectID": "tut_fsq.html#parameterized-evaluation",
    "href": "tut_fsq.html#parameterized-evaluation",
    "title": "Foursquare POI Data Example",
    "section": "Parameterized evaluation",
    "text": "Parameterized evaluation\nWith our core data transformation logic defined and parameterized, we can run the same transformation over the data at different H3 resolutions.\n\nt.do(latlng_h3(0), count_and_order)\n\n┌─────────────────┬─────────┐\n│      hexid      │   num   │\n│     varchar     │  int64  │\n├─────────────────┼─────────┤\n│ 8027fffffffffff │ 1106440 │\n└─────────────────┴─────────┘\n\n\n\nt.do(latlng_h3(1), count_and_order)\n\n┌─────────────────┬────────┐\n│      hexid      │  num   │\n│     varchar     │ int64  │\n├─────────────────┼────────┤\n│ 8128bffffffffff │    410 │\n│ 8126fffffffffff │   2835 │\n│ 81277ffffffffff │  25008 │\n│ 81267ffffffffff │  30173 │\n│ 8127bffffffffff │  31192 │\n│ 8126bffffffffff │ 313007 │\n│ 81263ffffffffff │ 703815 │\n└─────────────────┴────────┘\n\n\n\nt.do(latlng_h3(2), count_and_order)\n\n┌─────────────────┬────────┐\n│      hexid      │  num   │\n│     varchar     │ int64  │\n├─────────────────┼────────┤\n│ 8226f7fffffffff │   1051 │\n│ 822897fffffffff │   1574 │\n│ 8226e7fffffffff │   2092 │\n│ 822697fffffffff │   3206 │\n│ 822657fffffffff │   3656 │\n│ 82278ffffffffff │   5745 │\n│ 822637fffffffff │   6113 │\n│ 8226b7fffffffff │   8115 │\n│ 8226a7fffffffff │  14692 │\n│ 822617fffffffff │  15879 │\n│ 82279ffffffffff │  22247 │\n│ 82261ffffffffff │  26908 │\n│ 822677fffffffff │  32458 │\n│ 8226affffffffff │  48212 │\n│ 822607fffffffff │  63129 │\n│ 822627fffffffff │  79629 │\n│ 822687fffffffff │ 107644 │\n│ 82268ffffffffff │ 132766 │\n│ 82260ffffffffff │ 168373 │\n│ 822757fffffffff │ 174499 │\n│ 82262ffffffffff │ 188452 │\n├─────────────────┴────────┤\n│ 21 rows        2 columns │\n└──────────────────────────┘",
    "crumbs": [
      "Tutorials",
      "Foursquare POI"
    ]
  },
  {
    "objectID": "ramble.html",
    "href": "ramble.html",
    "title": "AJ Rambles",
    "section": "",
    "text": "duckboat excels at simple, readable interactive work without new syntax\nother libraries excel at providing IDE support and type hinting.\nI’m not a user of the latter, so I’m less familiar with the benefits here. However, I am interested in understanding if there is a way to capture the benefits of each of these approaches.\nWhat would a best-of-both-worlds library/language look like?\nas i said, this library is experimental. i’m going hard in one direction as a way to explore the developer experience space. I’m also interested in using this project as a way to kick off discussions of how to build future libraries and languages to solve similar problems.",
    "crumbs": [
      "Development",
      "AJ Rambles"
    ]
  },
  {
    "objectID": "ramble.html#repr",
    "href": "ramble.html#repr",
    "title": "AJ Rambles",
    "section": "Repr",
    "text": "Repr\nmaybe provide a repr option to provide an alternative to avoid the computation Table('.../...', repr='bah'). Should it pass it down to derived objects? Maybe that’s too complicated",
    "crumbs": [
      "Development",
      "AJ Rambles"
    ]
  },
  {
    "objectID": "ramble.html#opener",
    "href": "ramble.html#opener",
    "title": "AJ Rambles",
    "section": "Opener",
    "text": "Opener\nAn alternative Python DataFrame library for SQL gremlins.\n\nyou think SQL is fine, especially if you can write composable snippets\nmaybe you lose some IDE and typing support, but I think you get a big win in terms of REPL/notebook programming (which is where i spend most of my time)\n\nor, an experiment in https://en.wiktionary.org/wiki/Cunningham%27s_Law\nDuckboat is a small DataFrame library…\nDuckboat is etc. It is small, in that it is a light wrapper around the DuckDB API. Not much to learn and the library gets out of your way.",
    "crumbs": [
      "Development",
      "AJ Rambles"
    ]
  },
  {
    "objectID": "lazy.html",
    "href": "lazy.html",
    "title": "Lazy Evaluation",
    "section": "",
    "text": "Since duckboat builds on top of DuckDB’s relational API, all expressions are lazily evaluated by default. This means that complex query expressions can be built up interactively and step by step, and when you are ready to evaluate the final expression (or any intermediate expressions), the query steps will be assembed and optimized by the query planner to allow for the most efficient execuation possible:\n\navoid materialzing intermediate tables\nSQL pushdown optimizations\nDuckDB streaming and out-of-core operations\n\n\nGotchas\n\ninteractive analysis that calls a repr or str method, like having a table be the last expression in a Jupyter notebook cell\nIDEs that inspect variables proactively will call the repr on objects, which will trigger query evaluation. this happens in Positron, for example\n\n\n\nExample",
    "crumbs": [
      "Lazy Evaluation"
    ]
  }
]